{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910028c2-1cbb-4f77-8bb0-d29cef6cab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7002e-b49e-4ee6-ac74-cdca62794e33",
   "metadata": {},
   "source": [
    "## Defining a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73960ee2-988b-40e2-82f3-a21a5334fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeAwareGAE(nn.Module):\n",
    "    def __init__(self, input_dim, edge_dim, hidden_dim, embedding_dim):\n",
    "        super(EdgeAwareGAE, self).__init__()\n",
    "        self.edge_transform = nn.Linear(edge_dim, hidden_dim)\n",
    "        self.encoder1 = GATv2Conv(\n",
    "            input_dim, \n",
    "            hidden_dim, \n",
    "            edge_dim=hidden_dim,\n",
    "            heads=1,\n",
    "            add_self_loops=False\n",
    "        )\n",
    "        self.encoder2 = GATv2Conv(\n",
    "            hidden_dim, \n",
    "            hidden_dim, \n",
    "            edge_dim=hidden_dim,\n",
    "            heads=1,\n",
    "            add_self_loops=False\n",
    "        )\n",
    "        self.embedding_layer = GATv2Conv(\n",
    "            hidden_dim, \n",
    "            embedding_dim,\n",
    "            edge_dim=hidden_dim,\n",
    "            heads=1,\n",
    "            add_self_loops=False\n",
    "        )\n",
    "        self.lin1 = torch.nn.Linear(embedding_dim * 2, edge_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, data):\n",
    "        z = self.encoder(data)\n",
    "        return self.decoder(z,data.edge_index)\n",
    "\n",
    "    def encoder(self,data):\n",
    "        # Encode edge attributes\n",
    "        transformed_edge_attr = self.edge_transform(data.edge_attr)\n",
    "        z = self.encoder1(data.x, data.edge_index, transformed_edge_attr)\n",
    "        z = F.relu(z)\n",
    "        z = self.encoder2(z, data.edge_index, transformed_edge_attr)\n",
    "        z = F.relu(z)\n",
    "        return self.embedding_layer(z, data.edge_index, transformed_edge_attr)\n",
    "        \n",
    "    def decoder(self, z, edge_index):\n",
    "        # Decode edge attributes based on the embeddings of the source and destination nodes\n",
    "        src_nodes = edge_index[0]\n",
    "        dst_nodes = edge_index[1]\n",
    "        edge_embeddings = torch.cat([z[src_nodes], z[dst_nodes]], dim=1)\n",
    "        return self.lin1(edge_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9d7267-5526-4bf6-93fd-159b4d24bca0",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f2a9c-bedf-4069-801b-20fcf094fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_orignal = pd.read_csv(\"all_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96dbaf9-94d5-4b7a-9691-acb68bc34ce6",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279ea1d3-8b2d-4d34-8905-2ea45d0b8a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for i in range(data_orignal[\"Month\"].min()+1,data_orignal[\"Month\"].max()):\n",
    "    data=data_orignal[data_orignal[\"Month\"]==i]\n",
    "    # Create a mapping for node IDs (to numerical indices)\n",
    "    all_ids = pd.concat([data['From_Account_id'], data['To_Account_id']]).unique()\n",
    "    node_map = {val: i for i, val in enumerate(all_ids)}\n",
    "    data['source_node'] = data['From_Account_id'].map(node_map)\n",
    "    data['target_node'] = data['To_Account_id'].map(node_map)\n",
    "    data['normalized_amount'] = np.log(data['amount']+1)\n",
    "    hour_of_month = (data[\"Day\"] - 1) * 24 + data[\"Hour\"]\n",
    "    data['sin_hour_month'] = np.sin(2 * np.pi * hour_of_month / data[\"Day\"].max()*24)\n",
    "    data['cos_hour_month'] = np.cos(2 * np.pi * hour_of_month / data[\"Day\"].max()*24)\n",
    "    edge_index = torch.tensor(data[['source_node', 'target_node']].values.T, dtype=torch.long)\n",
    "    edge_attr = torch.tensor(data[['normalized_amount',\"sin_hour_month\",\"cos_hour_month\"]].values, dtype=torch.float)\n",
    "\n",
    "    node_feature = pd.read_csv(f\"month-{i}-nodes.csv\")\n",
    "    node_feature[\"Unnamed: 0\"] = node_feature[\"Unnamed: 0\"].map(node_map)\n",
    "    node_feature = node_feature.sort_values(by='Unnamed: 0', ascending=True)\n",
    "    node_feature[\"Outgoing_amount\"] = np.log(node_feature[\"Outgoing_Amount\"]+1)\n",
    "    node_feature[\"Incoming_amount\"] = np.log(node_feature[\"Incoming_Amount\"]+1)\n",
    "    in_scaler = MinMaxScaler()\n",
    "    out_scaler = MinMaxScaler()\n",
    "    node_feature['in_degree_centrality'] = in_scaler.fit_transform(node_feature[['in_degree_centrality']])\n",
    "    node_feature['out_degree_centrality'] = out_scaler.fit_transform(node_feature[['out_degree_centrality']])\n",
    "    x = torch.tensor(node_feature[[\"Outgoing_amount\",\"Incoming_amount\",\"in_degree_centrality\",\"out_degree_centrality\"]].values,dtype=torch.float)\n",
    "    all_data.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr, num_nodes=len(all_ids)))\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5829e-5650-455b-a4b1-2994fcbb4a36",
   "metadata": {},
   "source": [
    "## Initialize the model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8c41a-1c64-48e0-ae07-ddae32879c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_edge_features = all_data[0].edge_attr.size(1) \n",
    "num_node_featuress = all_data[0].num_node_features\n",
    "model = EdgeAwareGAE(num_node_featuress,num_edge_features,hidden_dim,embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "epochs=20\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63eab3-a43e-43a0-9efa-0274bb49074c",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614007d-dca3-44b4-a225-dd07b2cc2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "    print(\"Epochs: \",i)\n",
    "    for month_idx, monthly_data in enumerate(all_data):\n",
    "        model.train()\n",
    "        \n",
    "        # Move monthly data to the device (GPU/CPU)\n",
    "        monthly_data = monthly_data.to(device)\n",
    "        \n",
    "        # Optimizer reset if necessary (optional)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstructed = model(monthly_data)\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        loss = F.mse_loss(reconstructed, monthly_data.edge_attr)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Month {month_idx + 1}, Loss: {loss.item()}\")\n",
    "        \n",
    "        # Optionally save the model after each month's training\n",
    "    torch.save(model.state_dict(), f\"gae_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19fbcf4-70f4-4143-883c-d9508ab1bcdf",
   "metadata": {},
   "source": [
    "## Loading Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02139b18-da88-4b6c-8886-eaf9520b08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('gae_model_14.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45811fa-7d57-49ea-be4c-7492121b3ece",
   "metadata": {},
   "source": [
    "## Extracting and Saving Node Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752bb485-68ed-4f2b-9879-195b789eb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_data[0] # for only 7 month data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model.encoder(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0ed11b-5c42-425b-a697-61c59a54370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_np = embeddings.cpu().numpy()\n",
    "np.save('7-month-node-embeddings.npy', embeddings_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7890b112-9829-4eea-8436-777357f61438",
   "metadata": {},
   "source": [
    "## Performing Anomaly Detection on node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c43d1-af7e-455f-b682-f722a68d94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('7-month-node-embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f127a8d-e3b4-4bb7-bf06-ba1dfe12269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(contamination=0.01, random_state=42)  # Adjust contamination rate\n",
    "anomalies = clf.fit_predict(embeddings)  # -1 for anomalies, 1 for normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb21b61-1fcb-414a-a3bf-0b116326d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46bce42-fe41-40c0-96cb-426640202112",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_indices = np.where(anomalies==-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d699b6-bf06-43a2-9702-9307b4c6b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(suspicious_indices) # Number of suspicious nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c38631-1714-4f16-b2cb-65b90f0d363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_7 = data_orignal[data_orignal[\"Month\"]==7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2ddc1-ba4e-48dc-b1da-5d37e9579335",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = pd.concat([month_7['From_Account_id'], month_7['To_Account_id']]).unique()\n",
    "node_map = {val: i for i, val in enumerate(all_ids)}\n",
    "month_7['source_node'] = month_7['From_Account_id'].map(node_map)\n",
    "month_7['target_node'] = month_7['To_Account_id'].map(node_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66363c0-568e-4eaa-91ff-23fe0b6e8539",
   "metadata": {},
   "source": [
    "## Getting suspicious transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e27bf-32e8-4f45-b1cb-3b862d4c4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_transactions = month_7[\n",
    "    (month_7['source_node'].isin(suspicious_indices)) &\n",
    "    (month_7['target_node'].isin(suspicious_indices))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf0469-65e5-4572-8b48-19ea22080631",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6cdb2-c98d-4512-9fdc-855e594c7fe7",
   "metadata": {},
   "source": [
    "## Creating a graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f842a-cdbb-4e29-b049-6a2ed336cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "# Iterate through the DataFrame rows and add edges to the graph\n",
    "for index, row in suspicious_transactions.iterrows():\n",
    "    G.add_edge(row['source_node'], row['target_node'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d8a0e-8b83-4d15-be74-3e102d992758",
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components = [G.subgraph(c).copy() for c in nx.weakly_connected_components(G) if len(c)>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1fb61-c892-4040-acb6-a5ed53b48204",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(connected_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceab4c72-ec7c-47d6-aab4-597bde97bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nx.draw(G[0], with_labels=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd2f63a-c968-49e0-82ba-828a6b3a59bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
